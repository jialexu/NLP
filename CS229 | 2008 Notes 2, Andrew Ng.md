# Stanford CS229 | 2008 Andrew Ng | Notes 2

## Today

- Linear regression

- Gradinet descent

- Normal equations

video of supervised learning, regression problem, Alvin driving vehicle.


Example:

notation: 
m = number of training examples;
x = input variables / features;
y = output variables / target variable;
(x,y) = training example;
(x(i),y(i)) = i-th training example;

Training set -> Learning algorithm -> h: hypothesis

h maps from input x to output y

<img width="515" alt="image" src="https://user-images.githubusercontent.com/38922328/163912819-38c39b8c-9cee-44a5-9750-543964870c49.png">

<img width="517" alt="image" src="https://user-images.githubusercontent.com/38922328/163913719-0d6eed6c-4112-475a-af41-6d3595ae3991.png">

